dbt_analytics_demo

Projeto completo com dbt (Data Build Tool), focado em boas prÃ¡ticas de engenharia analÃ­tica, integraÃ§Ã£o de mÃºltiplas fontes de dados e execuÃ§Ã£o automatizada em servidor Linux ou Docker com Apache Airflow.


---

âš™ï¸ Tecnologias e ferramentas

DBT Core 1.7.x

Apache Airflow 2.8.1 (via Docker)

PostgreSQL (local e remoto)

Shell Script (deploy automatizado)

Python (para carga auxiliar de dados)

CSV, Excel e JSON como fontes simuladas

Docker + Docker Compose



---

ğŸ“ Estrutura do Projeto

dbt_analytics_demo/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/           # Camada de preparaÃ§Ã£o (ephemeral)
â”‚   â”œâ”€â”€ marts/             # Camada analÃ­tica (view/table/incremental)
â”œâ”€â”€ macros/                # Macros reutilizÃ¡veis em Jinja
â”œâ”€â”€ snapshots/             # Snapshots de mudanÃ§a histÃ³rica
â”œâ”€â”€ seeds/                 # Dados estÃ¡ticos (vendedores.csv)
â”œâ”€â”€ extras/                # Fontes externas (metas.xlsx, filiais.json)
â”œâ”€â”€ scripts/               # Script de carga auxiliar
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ Docker/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ dbt_run_dag.py
â”‚   â”‚   â”œâ”€â”€ dbt_test_dag.py
â”‚   â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ logs/               # logs gerados pelo Airflow
â”‚   â””â”€â”€ requirements.txt


---

ğŸš€ Como executar localmente (modo tradicional)

1. Clone o projeto e instale o ambiente

git clone git@seu_repo/dbt_analytics_demo.git
cd dbt_analytics_demo
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

2. Configure seu profiles.yml

Arquivo padrÃ£o do DBT (em ~/.dbt/profiles.yml):

dbt_analytics_demo:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: postgres
      password: sua_senha
      port: 5432
      dbname: dbt_demo
      schema: public
      threads: 4

3. Carregue os dados

dbt seed                      # Carrega os seeds CSV
python scripts/load_extras.py  # Carrega Excel e JSON no banco

4. Execute o pipeline DBT

dbt run                       # Executa os modelos
dbt test                      # Roda testes automÃ¡ticos
dbt docs generate && dbt docs serve  # Gera a documentaÃ§Ã£o


---

ğŸ³ Como executar via Docker com Airflow

1. Acesse o diretÃ³rio do Docker

cd Docker

2. Crie o arquivo .env

EMAIL_SENDER=seuemail@gmail.com
EMAIL_RECEIVER=seuemail@gmail.com
AIRFLOW_ADMIN_EMAIL=admin@example.com
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW__CORE__FERNET_KEY=sua_chave_fernet

Gere a chave com:

python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

3. Suba o Airflow

docker compose up airflow-init
docker compose up -d

Acesse: http://localhost:8080

UsuÃ¡rio: admin@example.com
Senha: admin

4. ExecuÃ§Ã£o de comandos dbt dentro do container

docker exec -it airflow-scheduler bash
cd /opt/airflow/dbt_analytics_demo
dbt build
dbt test
dbt docs generate


---

âœ… Funcionalidades implementadas

[x] Seeds CSV (vendedores)

[x] Leitura de Excel (.xlsx) com pandas

[x] Leitura de JSON com Python

[x] Camada staging com materializaÃ§Ã£o ephemeral

[x] Marts com view, table e incremental

[x] Snapshots de alteraÃ§Ãµes (ex: status de clientes)

[x] Macros reutilizÃ¡veis em Jinja

[x] Testes automatizados

[x] Deploy automÃ¡tico com Git + Bash

[x] ExecuÃ§Ã£o agendada com cron ou Airflow

[x] Airflow com DAGs para dbt build e dbt test



---

ğŸ“š Recursos Ãºteis

DBT Docs â€“ Macros

dbt-utils Package

Jinja Filters

Curso gratuito oficial



---

âœ¨ Autor

Elias Rodrigues (earlog.dev)
Analista de Dados SÃªnior | Python + SQL | Engenharia de Dados
GitHub: github.com/eliasantoniorodrigues1
LinkedIn: linkedin.com/in/ear-345-


---

LicenÃ§a

MIT

